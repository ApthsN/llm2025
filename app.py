#app.py
import os
import gradio as gr
import requests

OLLAMA_URL = os.getenv("OLLAMA_URL", "http://localhost:11434")

def ask_model(prompt):
    try:
        response = requests.post(
            f"{OLLAMA_URL}/api/generate",
            json={
                "model": "llama3.2",
                "prompt": prompt,
                "stream": False
            }
        )
        data = response.json()
        return data.get("response", "‚ö†Ô∏è ‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏Ñ‡∏≥‡∏ï‡∏≠‡∏ö‡∏à‡∏≤‡∏Å‡πÇ‡∏°‡πÄ‡∏î‡∏• ‡∏´‡∏£‡∏∑‡∏≠‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏¢‡∏±‡∏á‡πÑ‡∏°‡πà‡∏ó‡∏≥‡∏á‡∏≤‡∏ô")
    except requests.exceptions.ConnectionError:
        return "‚ùå ‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏°‡∏ï‡πà‡∏≠‡∏Å‡∏±‡∏ö Ollama ‡πÑ‡∏î‡πâ ‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ß‡πà‡∏≤ Ollama ‡∏ó‡∏≥‡∏á‡∏≤‡∏ô‡∏≠‡∏¢‡∏π‡πà‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà"
    except Exception as e:
        return f"‚ùå ‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î: {e}"

with gr.Blocks(title="‡∏ú‡∏π‡πâ‡∏ä‡πà‡∏ß‡∏¢ AI ‡∏†‡∏≤‡∏©‡∏≤‡πÑ‡∏ó‡∏¢ (Offline)") as demo:
    gr.Markdown("## üß† ‡∏ú‡∏π‡πâ‡∏ä‡πà‡∏ß‡∏¢ AI ‡∏†‡∏≤‡∏©‡∏≤‡πÑ‡∏ó‡∏¢ (‡∏ó‡∏≥‡∏á‡∏≤‡∏ô‡∏≠‡∏≠‡∏ü‡πÑ‡∏•‡∏ô‡πå)")
    with gr.Column():
        input_box = gr.Textbox(label="‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°", placeholder="‡∏õ‡πâ‡∏≠‡∏ô‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°", lines=3)
        submit_btn = gr.Button("‡∏ñ‡∏≤‡∏°")
        output_box = gr.Textbox(label="‡∏Ñ‡∏≥‡∏ï‡∏≠‡∏ö", lines=10)
    submit_btn.click(fn=ask_model, inputs=input_box, outputs=output_box)

demo.launch(server_name="0.0.0.0", server_port=7860)
